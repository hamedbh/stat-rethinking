# Sampling the Imaginary

```{r}
#| label: setup
#| output: false
library(tidyverse)
library(rethinking)
theme_set(theme_light())
```

The chapter starts with a new take on a popular way to introduce Bayesian inference: a blood test for detecting vampires with 95% accuracy, so $\text{P}(\text{positive test}|\text{vampire}) = 0.95$. Occasionally it returns false positives, so $\text{P}(\text{positive test}|\text{mortal}) = 0.01$. And vampires are generally pretty rare, so $\text{P}(\text{vampire}) = 0.001$ If a person tests positive, how likely is it that they are actually a vampire?

$$
\begin{align}
\text{P}(\text{vampire}|\text{positive test}) &= 
    \frac{\text{P}(\text{positive test}|\text{vampire})\text{P}(\text{vampire})}
    {\text{P}(\text{positive test})} \\
\text{P}(\text{vampire}|\text{positive test}) &= 
    \frac{\text{P}(\text{positive test}|\text{vampire})\text{P}(\text{vampire})}
    {\text{P}(\text{positive test}|\text{vampire})\text{P}(\text{vampire}) + 
        \text{P}(\text{positive test}|\text{mortal})\text{P}(\text{mortal})} \\
&= \frac{0.95 \times 0.001}{(0.95 \times 0.001) + (0.01 \times 0.999)} \\
&\approx 0.087
\end{align}
$$

So there's about an 8.7% chance of the person being a vampire. 

NB. This is almost a ninety-fold increase in the probability from prior to posterior, so the test is really informative. Even that sort of increase still only gets the number to 8.7%.

RM then reframes this in a more explicitly Bayesian way with frequencies instead of probabilities.

1. Of 100,000 people there are 100 vampires; 
2. Of the 100 who are vampires, 95 will test positive; 
3. Of the 99,900 mortals, 999 of them will test positive. 

Then it's just arithmetic: 

$$
\begin{align}
\text{P}(\text{vampire}|\text{positive test})& = \frac{95}{95 + 999} \\
& = \frac{95}{1094} \\
& \approx 0.087
\end{align}
$$

That presentation is called the _natural frequencies_, and can be easier than working with the probabilities. This moves us on to sampling from distributions: once we have a reasonable number of samples we can convert them to probabilities. 

## Sampling from a grid-approximate posterior

First set up the probability grid (using the globe-tossing example). 

```{r}
d01 <- tibble(
  p = seq(0, 1, length.out = 1000), 
  prior = 1
) |> 
  mutate(likelihood = dbinom(6, 9, prob = p)) |> 
  mutate(posterior = (prior * likelihood)/sum(prior * likelihood))
d01
```

Now draw samples from `p` using the `posterior` probabilities. 

```{r}
set.seed(1411)
N <- 1e4
samples01 <- d01 |> 
  slice_sample(n = N, weight_by = posterior, replace = TRUE) |> 
  rowid_to_column("index") |> 
  select(index, p_sample = p)
samples01
```

Can plot this in a couple of ways. 

```{r}
# Plot by index, RM describes this as looking down on the posterior 
# from above
samples01 |> 
  ggplot(aes(index, p_sample)) + 
  geom_point(alpha = 0.3, colour = "steelblue") + 
  coord_cartesian(ylim = c(0, 1)) + 
  labs(x = "sample number", y = "proportion water (p)")
```


```{r}
# and then a density plot
samples01 |> 
  ggplot(aes(p_sample)) + 
  geom_density(bw = 0.008,  colour = "steelblue",  alpha = 0.4) + 
  labs(x = "proportion water (p)")
```

## Sampling to summarise

Now we can use the posterior to answer interesting questions. 

### Intervals of defined boundaries

How probable is it that $p < 0.5$?

We have the answer available from the probability grid: 

```{r}
d01 |> 
  filter(p < 0.5) |> 
  summarise(prob = sum(posterior))
```

But we can also get this from the samples (and in other cases this may be the only way to do it). 

```{r}
samples01 |> 
  summarise(prob = mean(p_sample < 0.5))
```

Now ask how probable is it that $0.5 < p < 0.75$?

```{r}
samples01 |> 
  summarise(prob = mean(0.5 < p_sample & p_sample < 0.75))
```

### Intervals of defined mass

Now we invert the previous question: we want to know which interval of values of $p$ will have a given posterior probability? RM calls this a _Compatibility Interval_ (to avoid the problematic terms "confidence" and "credibility"). 

This is straightforward if we want the interval to start/finish at specific points. 

```{r}
# find the lower 80% posterior probability
samples01 |> 
  summarise(q_0 = 0,  q_80 = quantile(p_sample, 0.8))

# find the middle 80% posterior probability
samples01 |> 
  summarise(q_10 = quantile(p_sample, 0.1), q_90 = quantile(p_sample, 0.9))
```

But there are many intervals that would contain 80%. A more useful interval is the narrowest one containing 80% of the posterior probability. For that we use `rethinking::HPDI()`. 

```{r}
HPDI(samples01[["p_sample"]], prob = 0.8)
```

Highest Posterior Density Interval (HPDI) is perhaps more informative, but it has a couple of drawbacks: 

1. More computationally expensive; 
2. Suffers from _simulation variance_, i.e. it's more sensitive to the size of the sample. 

Useful quote from RM: 

> Overall, if the choice of interval type makes a big difference, then you shouldn't be using intervals to summarise the posterior. 

### Point estimates

RM describes this as "hardly ever necessary and often harmful. It discards information."

## Sampliong to simulate prediction

Several good reasons given for sampling:

1. Model design; 
2. Model checking; 
3. Software validation;
4. Research design;
5. Forecasting.

### Dummy data

Back to the globe-tossing example. Can easily generate dummy data for the binomial with various parameters (i.e. $n$ and $p$ in the binomial likelihood).

```{r}
set.seed(1401)
N <- 1e5
dummy_w <- tibble(draws = rbinom(N, size = 9, prob = 0.7))
dummy_w
```


```{r}
dummy_w |>
    count(draws) |> 
    mutate(draws = factor(draws)) |> 
    ggplot(aes(draws, n)) + 
    geom_col(width = 0.08) + 
    scale_y_continuous(labels = scales::label_comma()) + 
    labs(x = "dummy water count", y = "Frequency")
```

### Model checking

Two considerations: 

#### Did the software work?

RM discusses _retrodiction_: how well do the model outputs correspond to the data used to produce them?

#### Is the model adequate?

For this we need the _Posterior Predictive Distribution_. RM describes "propagating the uncertainty" through the model. Example shows the difference between generating samples based on a single value of $p$ (e.g. the MAP estimate of 0.6 or 0.7) or sampling from all the possible values of $p$ proportionately according to their posterior probability. 

```{r}
ppd <- samples01 |> 
  mutate(
    w_PPD = rbinom(n = nrow(samples01), size = 9, prob = p_sample), 
    w_MAP = rbinom(n = nrow(samples01), size = 9, prob = 0.67)  
  )
ppd
```

```{r}
ppd |> 
  select(starts_with("w_")) |> 
  pivot_longer(cols = everything()) |> 
  mutate(name = str_sub(name, 3L)) |> 
  mutate(across(.fns = factor)) |> 
  group_by(name) |> 
  count(value) |> 
  ggplot(aes(value, n, fill = name)) + 
  geom_col(width = 0.12, position = position_dodge()) + 
  scale_y_continuous(labels = scales::label_comma()) + 
  scale_fill_manual(values = c("steelblue", "firebrick")) + 
  labs(
    title = "Different uncertainty in samples", 
    subtitle = "Comparing PPD samples with those using MAP estimate of p", 
    x = "Water count", 
    y = "Frequency", 
    fill = NULL
  )
```

## Summary

Some useful insights here, especially the emphasis on PPD checks to understand whether we have something useful in our model. 

## Practice

Need to set up a specific set of samples to use in the practice problems. 

```{r}
p_grid <- seq(0, 1, length.out = 1000)
prior <- rep(1, 1000)
likelihood <- dbinom(6, size = 9, prob = p_grid)
posterior <- (likelihood * prior) / sum(likelihood * prior)
set.seed(100)
hw_samples <- sample(p_grid, prob = posterior, size = 1e4, replace = TRUE)
```

### Easy

```{r}
# 3E1
mean(hw_samples < 0.2)

# 3E2
mean(hw_samples > 0.8)

# 3E3
mean(hw_samples > 0.2 & hw_samples < 0.8)

# 3E4 and 3E5
quantile(hw_samples, c(0.2, 0.8))

# 3E6
HPDI(hw_samples, prob = 0.66)

# 3E7
PI(hw_samples, prob = 0.66)
```

### Medium

#### 3M1. 

```{r}
hw_m_post <- tibble(p = seq(0, 1, length.out = 1000), prior = 1) |>
  mutate(likelihood = dbinom(8, 15, prob = p)) |> 
  mutate(posterior = (prior * likelihood)/sum(prior * likelihood))
```

#### 3M2. 

```{r}
hw_m_samples <- hw_m_post |> 
    sample_n(size = 1e4, replace = TRUE, weight = posterior) |> 
    select(p)

HPDI(hw_m_samples$p, 0.9)
```

#### 3M3. 

```{r}
hw_m_ppd <- hw_m_samples |> 
  mutate(w_PPD = rbinom(n = nrow(hw_m_samples), size = 15, prob = p))

hw_m_ppd_summary <- hw_m_ppd |> 
  count(w_PPD) |> 
  mutate(prob = n / sum(n))

sprintf(
  "Probability of seeing exactly 8 water in 15 tosses is %.2f", 
  hw_m_ppd_summary |> 
    filter(w_PPD == 8L) |> 
    pull(prob)
  )
```

Useful to plot it also. 

```{r}
hw_m_ppd_summary |> 
  mutate(w_PPD = factor(w_PPD)) |> 
  ggplot(aes(w_PPD, n)) + 
  geom_col(width = 0.08) + 
  scale_y_continuous(labels = scales::label_comma()) + 
  labs(x = "Water count", y = "Frequency")
```

#### 3M4. 

```{r}
hw_m_samples |> 
  mutate(draws = rbinom(nrow(hw_m_samples), size = 9, prob = p)) |> 
  summarise(answer = mean(draws == 6L))
```

#### 3M5. 

```{r}
# Start again with the better prior
hw_m_post_step <- tibble(p = seq(0, 1, length.out = 1000)) |> 
  mutate(prior = as.integer(p >= 0.5)) |>
  mutate(likelihood = dbinom(8, 15, prob = p)) |> 
  mutate(posterior = (prior * likelihood)/sum(prior * likelihood))

# Now draw samples and calculate the HPDI
hw_m_samples_step <- hw_m_post_step |> 
    sample_n(size = 1e4, replace = TRUE, weight = posterior) |> 
    select(p)

HPDI(hw_m_samples_step[["p"]], 0.9)

# Do the PPD check, including the plot
hw_m_ppd_step <- hw_m_samples_step |> 
  mutate(w_PPD = rbinom(n = nrow(hw_m_samples_step), size = 15, prob = p))

hw_m_ppd_summary_step <- hw_m_ppd_step |> 
  count(w_PPD) |> 
  mutate(prob = n / sum(n))

sprintf(
  "Probability of seeing exactly 8 water in 15 tosses is %.2f", 
  hw_m_ppd_summary_step |> 
    filter(w_PPD == 8L) |> 
    pull(prob)
  )

hw_m_ppd_summary_step |> 
  mutate(w_PPD = factor(w_PPD)) |> 
  ggplot(aes(w_PPD, n)) + 
  geom_col(width = 0.08) + 
  scale_y_continuous(labels = scales::label_comma()) + 
  labs(x = "Water count", y = "Frequency")

# Use these data to check probability of 6 water in 9 tosses
hw_m_samples_step |> 
  mutate(draws = rbinom(nrow(hw_m_samples_step), size = 9, prob = p)) |> 
  summarise(answer = mean(draws == 6L))
```

The main difference between the inferences is that the better prior discounts the possibility of seeing less than 50% water. 

#### 3M6. 

Our strategy will be to use some approximations and analysis to narrow down the range, and then test it with simulation. 

We know that when the number of trials, $n$, is large the normal approximation to the binomial will be quite accurate. So we would expect 99% of the posterior probability to be within $\pm 3\sigma$, where $\sigma$ is the standard deviation of that normal distribution. So we will want $\sigma = 1/120$.

The binomial posterior distribution has a closed form when we use a beta prior, so we will need to set that. We will also need to specify the mean so that we can solve for the variance, so let's use the results from the first globe-tossing experiment as our prior, i.e. $p \sim \text{Beta}(6, 3)$. We know that the posterior distribution for $p$ given some number of $W$ and $L$ tosses will be $p | W, L \sim \text{Beta}(W + 6, L + 3)$. Its mean will be $a/(a + b)$, and variance $\frac{ab}{(a + b)^2 (a + b + 1)}$ (where $a$ and $b$ are the updated parameters after the new experiment). We can then solve for the parameters $a = 2133$ and $b = 1066$, which implies c. 3,200 tosses. 

Now we verify with simulation. 

```{r}
estimate_post_width <- function(n) {
  W <- round(2 * n / 3)
  hw_m_post_acc <- tibble(p = seq(0, 1, length.out = 1000), prior = 1) |>
    mutate(likelihood = dbinom(W, n, prob = p)) |> 
    mutate(posterior = (prior * likelihood)/sum(prior * likelihood))
  
  # Now draw samples, calculate the PI, and get its width
  hw_m_samples_acc <- hw_m_post_acc |> 
    sample_n(size = 1e4, replace = TRUE, weight = posterior) |> 
    select(p)
  
  PI(hw_m_samples_acc[["p"]], 0.99) |> 
    reduce(~ .y - .x)
}

tibble(n = seq(2000, 4000, by = 100)) |> 
  mutate(width = map_dbl(n, estimate_post_width)) |> 
  ggplot(aes(n, width)) + 
  geom_point() + 
  geom_line() + 
  geom_hline(yintercept = 0.05, linetype = 2, alpha = 0.4)
```

It seems that 3,200 tosses is rather more than is required, as we get the desired width in the posterior 99% interval somewhere between 2,400 and 2,500. 

### Hard

Need to load up the births data. 

```{r}
data(homeworkch3)
head(birth1)
head(birth2)
```

#### 3H1. 

```{r}
boys <- sum(birth1 + birth2)
births <- length(birth1) + length(birth2)
hw_h_post <- tibble(p = seq(0, 1, length.out = 1000), prior = 1) |>
  mutate(likelihood = dbinom(boys, births, prob = p)) |> 
  mutate(posterior = (prior * likelihood)/sum(prior * likelihood))
hw_h_post |> 
  slice_max(posterior) |> 
  select(answer = p)
```

Compare to the frequentist MLE:

```{r}
(hw_h_post |> slice_max(posterior) |> pull(p)) - (boys / births)
```

#### 3H2. 

```{r}
hw_h_samples <- hw_h_post |> 
  sample_n(size = 1e4, weight = posterior, replace = TRUE) |> 
  select(p)
map(c(0.5, 0.89, 0.97), ~ HPDI(hw_h_samples[["p"]], .x))
```

#### 3H3. 

```{r}
tibble(draws = rbinom(1e4, 200, prob = hw_h_samples[["p"]])) |> 
  ggplot(aes(draws)) + 
  geom_density() + 
  geom_vline(xintercept = boys, colour = "red")
```

It seems an OK match for the data: its peak is at/near 111, most of the mass is near that point, fairly symmetrical. There's perhaps more mass than we would expect out in the tails. 

#### 3H4. 

```{r}
tibble(draws = rbinom(1e4, 100, prob = hw_h_samples$p)) |> 
  ggplot(aes(draws)) + 
  geom_density() + 
  geom_vline(xintercept = sum(birth1), colour = "red")
```

This is no longer performing that well, putting most of the density well above the value seen in the data. 

#### 3H5. 

```{r}
boy_after_girl <- birth2[birth1 == 0L]
tibble(draws = rbinom(1e4, length(boy_after_girl), prob = hw_h_samples$p)) |> 
  ggplot(aes(draws)) + 
  geom_density() + 
  geom_vline(xintercept = sum(boy_after_girl), colour = "red")
```

Our model expects far fewer boys to be born than we actually see. Possibly this is because our assumption of independence between the first and second births is faulty. 

### Week 1 Homework

#### Q1. 

```{r}
plot_hw_globe <- function(w, l, prior = rep(1, length(p_grid))) {
  tibble(p = p_grid) |> 
    mutate(likelihood = dbinom(w, w + l, prob = p_grid)) |> 
    mutate(posterior = (prior * likelihood) / sum((prior * likelihood))) |> 
    ggplot(aes(p, posterior)) + 
    geom_line() + 
    labs(y = NULL) + 
    theme(axis.text.y = element_blank(), axis.ticks.y = element_blank())
}
plot_hw_globe(4, 11)
```

#### Q2. 

```{r}
plot_hw_globe(4, 2, if_else(p_grid < 0.5, 0, 1))
```

#### Q3. 

```{r}
set.seed(830)
tibble(p = p_grid) |> 
  mutate(prior = if_else(p_grid < 0.5, 0, 1)) |> 
  mutate(likelihood = dbinom(4, 6, prob = p_grid)) |> 
  mutate(posterior = (prior * likelihood) / sum((prior * likelihood))) |> 
  sample_n(size = 1e4, replace = TRUE, weight = posterior) |> 
  reframe(
    tibble(
      name = c("PI_low", "PI_upp", "HPDI_low", "HPDI_upp"),
      value = c(PI(p), HPDI(p))
    )
  ) |>
  pivot_wider() |> 
  mutate(PI_width = PI_upp - PI_low, HPDI_width = HPDI_upp - HPDI_low)
```

The PI is wider because it needs to be centred, with equal probability density on either side of the interval. So it has to exclude the area starting at 0.5, in order to keep 5.5% of the density to the left of the interval. Whereas the HPDI can include that area, which has fairly high density, to build the narrowest possible 89% interval. 

Neither of those intervals tell us anything about the discontinuity at 0.5 though, which is why we need the whole posterior. 

#### Q4. 

```{r}
set.seed(846)
sample_with_bias <- function(N, true_p = 0.7, err_pct = 0.2) {
  tibble(
    i = seq_len(N),
    water = rbinom(N, 1, prob = true_p * (1 - err_pct))
  )
}
sample_with_bias(1e5) |> 
  summarise(across(water, mean))
```

We estimate about 56% of the globe as water. This makes intuitive sense, as $0.56 = 0.7 \times 4/5$. 

Now our job is to recover the true proportion of water from the biased sample. 

```{r}
set.seed(851)
hw_biased_sample <- sample_with_bias(20)
hw_biased_sample |> 
  summarise(across(water, sum))
```

```{r}
hw_biased_w <- sum(hw_biased_sample[["water"]])
tibble(p = p_grid) |> 
  mutate(prior = dbeta(p_grid, 1, 1)) |> 
  mutate(
    biased_prob = dbinom(hw_biased_w, 20, prob = p_grid), 
    # The next line removes the bias from the sample by adjusting the
    # probability: essentially it accounts for the fact that we were less likely
    # to see water, which lowers the density at that point.
    unbiased_prob = dbinom(hw_biased_w, 20, prob = p_grid * 0.8)
  ) |> 
  mutate(
    biased_post = (prior * biased_prob) / sum((prior * biased_prob)), 
    unbiased_post = (prior * unbiased_prob) / sum((prior * unbiased_prob))
  ) |> 
  pivot_longer(ends_with("post")) |> 
  mutate(name = str_extract(name, "[a-z]+")) |> 
  ggplot(aes(p, value, colour = name)) + 
  geom_line(size = 1.5) + 
  scale_colour_manual(values = c("grey20", "steelblue")) + 
  labs(y = NULL) + 
  theme(
    axis.text.y = element_blank(), 
    axis.ticks.y = element_blank(), 
    legend.position = "bottom"
  )
```
